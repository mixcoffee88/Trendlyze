from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium import webdriver

import json, time, os, platform, logging
from config import settings
from utils.result_limiter import ResultLimiter
from utils.common import is_within_days, replace_date, make_result, wait_ready_state
from crawler.crawling_manager import CrawlingManager
from models.elements import InputField, ActionButton
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

SITE_NAME = "OpenAds"
URL = "https://www.openads.co.kr/home"
LIMIT = 9
TARGET_LIST = [
    {"catCd": "CC49", "catNm": "íŠ¸ëœë“œ"},
    {"catCd": "CC92", "catNm": "ë¹„ì§€ë‹ˆìŠ¤"},
    {"catCd": "CC58", "catNm": "ë§ˆì¼€íŒ… ì „ëµ"},
    {"catCd": "CC68", "catNm": "ë””ì§€í„¸ ê´‘ê³ "},
    {"catCd": "CC107", "catNm": "ë°ì´í„°"},
    {"catCd": "CC97", "catNm": "ë¦¬í¬íŠ¸ìë£Œì‹¤"},
    {"catCd": "CC82", "catNm": "ì»¤ë¦¬ì–´"},
    {"catCd": "CC75", "catNm": "ì—…ë¬´ìŠ¤í‚¬"},
    {"catCd": "CC86", "catNm": "ìê¸°ê°œë°œ"},
    {"catCd": "CC114", "catNm": "ì˜¤ë“œë¦¬ì±…ë°©"},
    {"catCd": "CC121", "catNm": "ì˜¤ìŠ¤í† ë¦¬"},
]

DATA_CALL_SCRIPT = """
    const formData = new FormData();
    formData.append('categoryCode', '{categoryCode}');
    formData.append('subCategoryCode', '');
    formData.append('offset', {offset});
    formData.append('limit', {limit});

    fetch('https://www.openads.co.kr/content/cardContent', {{
        method: 'POST',
        body: formData,
        credentials: 'include'  // ì¿ í‚¤ ë“± ì¸ì¦ ìœ ì§€ ì‹œ í•„ìš”
    }}).then(response => response.text())
    .then(result => {{
        console.log("âœ… ë¡œê·¸ì¸ ê²°ê³¼:", result);
        window.contentResult = result;
    }}).catch(err => {{
        console.error("âŒ ì—ëŸ¬:", err);
        window.contentResult = "ERROR";
    }});
"""


def crawling(driver: CrawlingManager):
    driver.browser.get(URL)
    WebDriverWait(driver.browser, 5).until(lambda d: "ì˜¤í”ˆì• ì¦ˆ" in d.title)
    limiter = ResultLimiter()

    for target in TARGET_LIST:
        logger.debug(f"{target['catNm']} ì§„í–‰ ì‹œì‘")
        is_loop = True
        page_num = 0
        while is_loop:
            # íŠ¸ë Œë“œ ê¸°ë³¸ê°’ CC49, 9ê°œ
            offset = page_num * LIMIT
            page_num += 1
            time.sleep(0.5)  # ì„œë²„ì—ì„œ ë§‰íìˆ˜ë„ ìˆìœ¼ë‹ˆê¹ í˜¸ì¶œì „ì— ì ê¹
            driver.browser.execute_script(
                DATA_CALL_SCRIPT.format(
                    categoryCode=target["catCd"], offset=offset, limit=LIMIT
                )
            )
            logger.debug(f"{target['catNm']} / {offset} í˜¸ì¶œ ì§„í–‰")

            result = None
            for _ in range(20):  # 10ì´ˆê¹Œì§€ ëŒ€ê¸°
                result = driver.browser.execute_script("return window.contentResult")
                if result:
                    break
                time.sleep(0.5)

            if result and result != "ERROR":
                try:
                    json_data = json.loads(result)
                    if json_data.get("success", False):
                        message = json_data.get("message", {})
                        cards = message.get("cards", [])
                        total_count = message.get("totalContsCnt", 0)

                        if offset >= total_count:
                            logger.debug(
                                f"âœ… ì¢…ë£Œ ì¡°ê±´ ë„ë‹¬: offset {offset} â‰¥ total {total_count}"
                            )
                            is_loop = False
                            break

                        for j in cards:
                            try:
                                pub_date = j.get("pubDtime", "")
                                if is_within_days(
                                    pub_date, day=settings.CRAWLING_LIMIT_DAY
                                ):
                                    result_item = make_result(
                                        SITE_NAME,
                                        target,
                                        j.get("title"),
                                        f'https://www.openads.co.kr/content/contentDetail?contsId={j["contsId"]}',
                                        replace_date(pub_date),
                                        driver.getIdx(),
                                    )
                                    if not limiter.append(result_item):
                                        logger.debug(
                                            f"ğŸ›‘ ë””ë²„ê·¸ ëª¨ë“œ: {target['catCd']} ìˆ˜ì§‘ ì œí•œ ë„ë‹¬, ì¤‘ë‹¨"
                                        )
                                        is_loop = False
                                        break
                                else:
                                    logger.debug(
                                        f"â© ë¬´ì‹œ ({settings.CRAWLING_LIMIT_DAY}ì¼ ì´ˆê³¼): {pub_date}"
                                    )
                                    is_loop = False
                                    break
                            except Exception as e:
                                logger.error(f"âŒ ì¹´ë“œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                                continue
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    is_loop = False
                    break
            else:
                logger.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ê²°ê³¼:", result)
                is_loop = False
                break
        logger.debug(f"{target['catNm']} ì§„í–‰ ì¢…ë£Œ")

    driver.closeExtraTabs()
    limiter.results = driver.crawing_content(limiter.results)
    driver.saveResults(SITE_NAME, limiter.results)
