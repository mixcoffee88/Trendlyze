from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium import webdriver
from config import settings

import json, time, os, platform, re, logging
from utils.result_limiter import ResultLimiter
from utils.common import is_within_days, replace_date, make_result, wait_ready_state
from crawler.CrawlingManager import CrawlingManager
from models.elements import InputField, ActionButton

logger = logging.getLogger(__name__)

SITE_NAME = "DIGITAL INSIGHT"
URL = "https://ditoday.com/article/page/{page_num}/?order=latest"


def crawling(driver: CrawlingManager):

    page_num = 0
    isLoop = True
    limiter = ResultLimiter()

    while isLoop:
        page_num += 1
        logger.debug(f"page_num : {page_num}")
        driver.browser.get(URL.format(page_num=page_num))

        # ë¡œë“œì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸
        WebDriverWait(driver.browser, 10).until(wait_ready_state())

        rows = driver.browser.find_elements(By.CSS_SELECTOR, "li.article-loop-item")
        for row in rows:
            try:
                start_time = time.time()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡

                date_text = row.find_element(
                    By.CSS_SELECTOR, "div.entry-meta > div.entry-info > span.entry-date"
                ).text.strip()

                if not is_within_days(date_text, day=settings.CRAWLING_LIMIT_DAY):
                    logger.debug(
                        f"â© ë¬´ì‹œ ({settings.CRAWLING_LIMIT_DAY}ì¼ ì´ˆê³¼): {date_text}"
                    )
                    isLoop = False
                    break

                title_el = row.find_element(
                    By.CSS_SELECTOR, "div.entry-meta > h3.entry-title > a"
                )

                href = title_el.get_attribute("href")
                title = title_el.text.strip()

                result_item = make_result(
                    SITE_NAME,
                    None,
                    title,
                    href,
                    replace_date(date_text),
                    driver.getIdx(),
                )

                if not limiter.append(result_item):
                    logger.debug(f"ğŸ›‘ ë””ë²„ê·¸ ëª¨ë“œ: ìˆ˜ì§‘ ì œí•œ ë„ë‹¬, ì¤‘ë‹¨")
                    isLoop = False
                    break

                elapsed_time = time.time() - start_time  # ê²½ê³¼ ì‹œê°„ ê³„ì‚°
                logger.debug(f"â±ï¸ {href} ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
            except Exception as e:
                logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue

    driver.closeExtraTabs()
    limiter.results = driver.crawing_content(limiter.results)
    driver.saveResults(SITE_NAME, limiter.results)
